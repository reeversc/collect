{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "    google-genai==0.2.2 \\\n",
    "    matplotlib==3.10.0 \\\n",
    "    pillow==11.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images already downloaded\n",
      "['images/clown-fish.png', 'images/dotted-fish.png', 'images/many-fish.png', 'images/fish-home.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# check if the images directory exists\n",
    "if not os.path.exists(\"./images\"):\n",
    "    os.mkdir(\"./images\")\n",
    "\n",
    "png_paths = [str(x) for x in Path(\"./images\").glob(\"*.png\")]\n",
    "\n",
    "# check if we have expected images, otherwise download\n",
    "if len(png_paths) >= 4:\n",
    "    print(\"Images already downloaded\")\n",
    "else:\n",
    "    print(\"Downloading images...\")\n",
    "    # download images from the web\n",
    "    files = [\"clown-fish.png\", \"dotted-fish.png\", \"many-fish.png\", \"fish-home.png\"]\n",
    "    for file in files:\n",
    "        url = f\"https://github.com/aurelio-labs/cookbook/blob/main/gen-ai/google-ai/gemini-2/images/{file}?raw=true\"\n",
    "        response = requests.get(url, stream=True)\n",
    "        with open(f\"./images/{file}\", \"wb\") as f:\n",
    "            for block in response.iter_content(1024):\n",
    "                if not block:\n",
    "                    break\n",
    "                f.write(block)\n",
    "    png_paths = [str(x) for x in Path(\"./images\").glob(\"*.png\")]\n",
    "\n",
    "print(png_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see each of these images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# we use matplotlib to arrange the images in a grid\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 8))\n",
    "for ax, path in zip(axs.flat, png_paths):\n",
    "    img = Image.open(path)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(path)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Gemini to describe these images, detect the various fish and corals, and see how precisely Gemini can identify the various objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start simple by asking Gemini to simply describe what it finds in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "with BytesIO(open(png_paths[0], \"rb\").read()) as img_bytes:\n",
    "    # note: resizing is optional, but it helps with performance\n",
    "    image = Image.open(img_bytes).resize(\n",
    "        (1024, int(1024 * img.size[1] / img.size[0])),\n",
    "        Image.Resampling.LANCZOS\n",
    "    )\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup our config. Within it we need:\n",
    "\n",
    "* The `system_instruction` describing that we need the LLM to draw bounding boxes around something.\n",
    "* Our `safety_settings` which we will keep relatively loose to avoid overly sensitive guardrails against our inputs.\n",
    "* Set `temperature` for more/less creative output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "system_instruction = (\n",
    "    \"Describe what you see in this image, identify any fish or coral species \"\n",
    "    \"in the image and tell us how many of each you can see.\"\n",
    ")\n",
    "\n",
    "safety_settings = [\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        threshold=\"BLOCK_ONLY_HIGH\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "config = types.GenerateContentConfig(\n",
    "    system_instruction=system_instruction,\n",
    "    temperature=0.1,\n",
    "    safety_settings=safety_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before generating _anything_ we need to initialize our client, for this we will need a Google API key. To get a key, you can setup an account in [Google AI Studio](https://aistudio.google.com).\n",
    "\n",
    "After you have your account and API key, we initialize our [`google.genai` client](https://github.com/googleapis/python-genai):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from google import genai\n",
    "\n",
    "# pass your API key here\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\") or getpass(\n",
    "    \"Enter Google API Key: \"\n",
    ")\n",
    "# initialize our client\n",
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "model_id = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "# run our query against the clownfish image\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=[\n",
    "        \"Tell me what is here\",\n",
    "        image\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Check output\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = (\n",
    "    \"Return bounding boxes as a JSON array with labels. Never \"\n",
    "    \"return masks or code fencing. Limit to 25 objects. \"\n",
    "    \"If an object is present multiple times, label them according \"\n",
    "    \"to their scientific and popular name.\"\n",
    ")  # modifying this prompt much seems to damage performance\n",
    "\n",
    "config = types.GenerateContentConfig(\n",
    "    system_instruction=system_instruction,\n",
    "    temperature=0.1,\n",
    "    safety_settings=safety_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=[\n",
    "        \"Highlight the different fish in the image\",\n",
    "        image\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = (\n",
    "    \"Return bounding boxes as a JSON array with labels. Never \"\n",
    "    \"return masks or code fencing. Limit to 25 objects. \"\n",
    "    \"If an object is present multiple times, label them according \"\n",
    "    \"to their scientific and popular name.\"\n",
    ")  # modifying this prompt much seems to damage performance\n",
    "\n",
    "config = types.GenerateContentConfig(\n",
    "    system_instruction=system_instruction,\n",
    "    temperature=0.05,\n",
    "    safety_settings=safety_settings,\n",
    "    frequency_penalty=1.0,  # reduce repetition\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=[\n",
    "        \"Highlight the different fish in the image\",\n",
    "        image\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "json_pattern = re.compile(r'```json\\n(.*?)```', re.DOTALL)\n",
    "json_output = json_pattern.search(response.text).group(1)\n",
    "\n",
    "# convert our json string to a list of dicts\n",
    "bounding_boxes = json.loads(json_output)\n",
    "bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(llm_output: str) -> list[dict]:\n",
    "    json_output = json_pattern.search(llm_output).group(1)\n",
    "    return json.loads(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw, ImageColor\n",
    "\n",
    "colors = [colorname for (colorname, colorcode) in ImageColor.colormap.items()]\n",
    "\n",
    "def plot_bounding_boxes(image: Image, llm_output: str) -> Image:\n",
    "    # avoid modifying the original image\n",
    "    img = image.copy()\n",
    "    # we need the image size to convert normalized coords to absolute below\n",
    "    width, height = img.size\n",
    "    # init drawing object\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    # parse out the bounding boxes JSON from markdown\n",
    "    bounding_boxes = parse_json(llm_output=llm_output)\n",
    "\n",
    "    # iterate over LLM defined bounding boxes\n",
    "    for i, bounding_box in enumerate(bounding_boxes):\n",
    "      # set diff color for each box\n",
    "      color = colors[i % len(colors)]\n",
    "\n",
    "      # from normalized to absolute coords\n",
    "      abs_y1 = int(bounding_box[\"box_2d\"][0]/1000 * height)\n",
    "      abs_x1 = int(bounding_box[\"box_2d\"][1]/1000 * width)\n",
    "      abs_y2 = int(bounding_box[\"box_2d\"][2]/1000 * height)\n",
    "      abs_x2 = int(bounding_box[\"box_2d\"][3]/1000 * width)\n",
    "\n",
    "      # coords might be going right to left, swap if so\n",
    "      if abs_x1 > abs_x2:\n",
    "        abs_x1, abs_x2 = abs_x2, abs_x1\n",
    "      if abs_y1 > abs_y2:\n",
    "        abs_y1, abs_y2 = abs_y2, abs_y1\n",
    "\n",
    "      # draw the bounding boxes on our Draw object\n",
    "      draw.rectangle(\n",
    "          ((abs_x1, abs_y1), (abs_x2, abs_y2)), outline=color, width=2\n",
    "      )\n",
    "\n",
    "      # draw text labels\n",
    "      if \"label\" in bounding_box:\n",
    "        draw.text((abs_x1 + 2, abs_y1 - 14), bounding_box[\"label\"], fill=color)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bounding_boxes(image, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=[\n",
    "        \"Highlight the different corals in the image\",\n",
    "        image\n",
    "    ],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bounding_boxes(image, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=[\n",
    "        \"Highlight the different clownfish in the image\",\n",
    "        image\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "plot_bounding_boxes(image, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=[\n",
    "        \"Highlight any cleaner wrasse in this image\",\n",
    "        image\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "plot_bounding_boxes(image, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with BytesIO(open(png_paths[1], \"rb\").read()) as img_bytes:\n",
    "    # note: resizing is optional, but it helps with performance\n",
    "    image = Image.open(img_bytes).resize(\n",
    "        (1024, int(1024 * img.size[1] / img.size[0])),\n",
    "        Image.Resampling.LANCZOS\n",
    "    )\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=[\n",
    "        \"Highlight any fish in this image\",\n",
    "        image\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "plot_bounding_boxes(image, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=[\n",
    "        \"What is the big fish in the middle of the image? Please highlight it.\",\n",
    "        image\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "plot_bounding_boxes(image, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with BytesIO(open(png_paths[2], \"rb\").read()) as img_bytes:\n",
    "    # note: resizing is optional, but it helps with performance\n",
    "    image = Image.open(img_bytes).resize(\n",
    "        (1024, int(1024 * img.size[1] / img.size[0])),\n",
    "        Image.Resampling.LANCZOS\n",
    "    )\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=[\n",
    "        \"Highlight any fish in this image\",\n",
    "        image\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "plot_bounding_boxes(image, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with BytesIO(open(png_paths[2], \"rb\").read()) as img_bytes:\n",
    "    # note: resizing is optional, but it helps with performance\n",
    "    image = Image.open(img_bytes).resize(\n",
    "        (1024, int(1024 * img.size[1] / img.size[0])),\n",
    "        Image.Resampling.LANCZOS\n",
    "    )\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=[\n",
    "        \"Highlight the corals in this image\",\n",
    "        image\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "plot_bounding_boxes(image, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with BytesIO(open(png_paths[3], \"rb\").read()) as img_bytes:\n",
    "    # note: resizing is optional, but it helps with performance\n",
    "    image = Image.open(img_bytes).resize(\n",
    "        (1024, int(1024 * img.size[1] / img.size[0])),\n",
    "        Image.Resampling.LANCZOS\n",
    "    )\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=[\n",
    "        \"Where is the fish hiding in this image?\",\n",
    "        image\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "plot_bounding_boxes(image, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = (\n",
    "    \"Describe what you see in this image, identify any fish or coral species \"\n",
    "    \"in the image and tell us how many of each you can see.\"\n",
    ")\n",
    "\n",
    "config = types.GenerateContentConfig(\n",
    "    system_instruction=system_instruction,\n",
    "    temperature=0.1,\n",
    "    safety_settings=safety_settings,\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=[\n",
    "        \"Explain what this image contains, what is happening, and what is the location?\",\n",
    "        image\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=[\n",
    "        \"What is your best guess as to the exact location of this shipwreck?\",\n",
    "        image\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "Markdown(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
